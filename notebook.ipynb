{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import vmap, jit, lax\n",
    "import jax.numpy as jnp\n",
    "from jax.tree_util import tree_leaves\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data import load_subject, make_kfolds\n",
    "from src.utils import CONFIG\n",
    "from src.train import hyperparam_fn\n",
    "from src.plots import plot_brain, plot_multiples, make_halves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "image_size = 28   #128 # CONFIG['image_size']\n",
    "latent_dim = 128\n",
    "kernel_size = 4\n",
    "lr = 1e-2\n",
    "depth = 2  # also deconv depth\n",
    "max_channels = 2 ** (depth + 2)\n",
    "precision = jnp.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" subject = load_subject('subj05', image_size=image_size, precision=precision)\\nhyperparams = hyperparam_fn()\\nkfolds = make_kfolds(subject, hyperparams)\\nloader, _ = next(kfolds) \""
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" subject = load_subject('subj05', image_size=image_size, precision=precision)\n",
    "hyperparams = hyperparam_fn()\n",
    "kfolds = make_kfolds(subject, hyperparams)\n",
    "loader, _ = next(kfolds) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tfds.as_numpy(tfds.load('mnist', batch_size=-1))\n",
    "# digits = mnist['train']['image'].reshape(-1, 16, 28, 28, 1) / 255.0\n",
    "# fashion_mnist = tfds.as_numpy(tfds.load('fashion_mnist', batch_size=-1))\n",
    "# digits = fashion_mnist['train']['image'].reshape(-1, 16, 28, 28, 1) / 255.0\n",
    "omniglot = tfds.as_numpy(tfds.load('omniglot', batch_size=-1))\n",
    "digits = omniglot['train']['image'].reshape(-1, 16, 105, 105, 3) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def conv2d(x, w):\n",
    "    return jax.lax.conv_general_dilated(\n",
    "        x, w, \n",
    "        window_strides=(2, 2), \n",
    "        padding='SAME',\n",
    "        dimension_numbers=(\"NHWC\", \"HWIO\", \"NHWC\"))\n",
    "\n",
    "@jit\n",
    "def upscale_nearest_neighbor(x, scale_factor=2):\n",
    "    # Assuming x has shape (batch, height, width, channels)\n",
    "    b, h, w, c = x.shape\n",
    "    x = x.reshape(b, h, 1, w, 1, c)\n",
    "    x = lax.tie_in(x, jnp.broadcast_to(x, (b, h, scale_factor, w, scale_factor, c)))\n",
    "    return x.reshape(b, h * scale_factor, w * scale_factor, c)\n",
    "\n",
    "@jit\n",
    "def deconv2d(x, w):\n",
    "    x_upscaled = upscale_nearest_neighbor(x)\n",
    "    return lax.conv_transpose(\n",
    "        x_upscaled, w, \n",
    "        strides=(1, 1), \n",
    "        padding='SAME',\n",
    "        dimension_numbers=(\"NHWC\", \"HWIO\", \"NHWC\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, w, b, activation=jax.nn.gelu):\n",
    "    return activation(conv2d(x, w) + b)\n",
    "\n",
    "def deconv(x, w, b, activation=jax.nn.gelu):\n",
    "    return activation(deconv2d(x, w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, params):\n",
    "    conv_params = params['encoder']['conv']\n",
    "    fc_params = params['encoder']['fc']\n",
    "    for idx, (w, b) in enumerate(conv_params):\n",
    "        x = conv(x, w, b)\n",
    "    x = x.reshape(x.shape[0], (image_size // (2 ** depth)) ** 2 * max_channels)\n",
    "    x = jnp.dot(x, fc_params[0]) + fc_params[1]\n",
    "    return jax.nn.gelu(x)\n",
    "\n",
    "def decoder(z, params):\n",
    "    deconv_params = params['decoder']['deconv']\n",
    "    fc_params = params['decoder']['fc']\n",
    "    x = jnp.dot(z, fc_params[0]) + fc_params[1]\n",
    "    x = x.reshape(x.shape[0], (image_size // (2 ** depth)), (image_size // (2 ** depth)), max_channels)\n",
    "    for idx, (w, b) in enumerate(deconv_params):\n",
    "        x = deconv(x, w, b)\n",
    "    return jnp.clip(x, 0, 1)   # sigmoid might be better, but this is faster\n",
    "\n",
    "\n",
    "\n",
    "def init_layer_params(key, shape, scale=1e-1):\n",
    "    w = jax.random.normal(key, shape) * scale\n",
    "    b = jnp.zeros(shape[-1])\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def init_encoder(key, scale=1e-1):\n",
    "    conv_shapes = [\n",
    "        (kernel_size, kernel_size, 3 if i == 0 else 2 ** (i + 2), 8 if i == 0 else 2 ** (i + 3))\n",
    "        for i in range(depth)\n",
    "    ]\n",
    "    conv_params = [init_layer_params(key, shape, scale) for shape in conv_shapes]\n",
    "    fc_shape = (max_channels * (image_size // (2 ** depth)) ** 2, latent_dim)\n",
    "    fc_params = init_layer_params(key, fc_shape, scale)\n",
    "    return {'conv': conv_params, 'fc': fc_params}\n",
    "\n",
    "\n",
    "def init_decoder(key, scale=1e-1):\n",
    "    deconv = [\n",
    "        (kernel_size, kernel_size, 2 ** (depth - i + 2), 3 if i == depth - 1 else 2 ** (depth - i + 1))\n",
    "        for i in range(depth)\n",
    "    ]\n",
    "    deconv_params = [init_layer_params(key, shape, scale) for shape in deconv]\n",
    "    fc_shape = (latent_dim, max_channels * (image_size // (2 ** depth)) ** 2)\n",
    "    fc_params = init_layer_params(key, fc_shape, scale)\n",
    "    return {'deconv': deconv_params, 'fc': fc_params}\n",
    "\n",
    "def init_params(key):\n",
    "    key_encoder, key_decoder = jax.random.split(key)\n",
    "    return {'encoder': init_encoder(key_encoder), 'decoder': init_decoder(key_decoder)}\n",
    "\n",
    "\n",
    "@jit\n",
    "def loss_fn(params, x):\n",
    "    z = encoder(x, params)\n",
    "    x_hat = decoder(z, params)\n",
    "    return jnp.mean((x - x_hat) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(jax.random.PRNGKey(0))\n",
    "params = init_params(subkey)\n",
    "params = jax.tree_map(lambda x: x.astype(precision), params)\n",
    "n_params = sum([np.prod(v.shape) for v in tree_leaves(params)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206515"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optax.adamw(lr)\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "def update_fn(params, x, opt_state):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, x)\n",
    "    updates, opt_state = opt.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return loss, params, opt_state\n",
    "\n",
    "eval_batch = digits[0]   # next(loader)[2]\n",
    "def train_loop(params, opt_state):\n",
    "    for i in range(10000):\n",
    "        _, _, img = next(loader)\n",
    "        img = digits[i]\n",
    "        loss, params, opt_state = update_fn(params, img, opt_state)\n",
    "        eval_pred = decoder(encoder(eval_batch, params), params)\n",
    "        # eval_imgs = make_halves(eval_batch, eval_pred)\n",
    "        plot_multiples(eval_pred, 5, info_bar=[f\"step : {i:05d}\",\n",
    "                                               f\"loss : {loss:.3f}\",\n",
    "                                               f\"params : {n_params:,}\",\n",
    "                                               f\"latent_dim : {latent_dim}\"])\n",
    "    return params, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "InconclusiveDimensionOperation",
     "evalue": "Cannot divide evenly the sizes of shapes (16, 27, 27, 16) and (16, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInconclusiveDimensionOperation\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m/Users/syrkis/code/neuroscope/notebook.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_loop(params, opt_state)\n",
      "\u001b[1;32m/Users/syrkis/code/neuroscope/notebook.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10000\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m#_, _, img = next(loader)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     img \u001b[39m=\u001b[39m digits[i]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loss, params, opt_state \u001b[39m=\u001b[39m update_fn(params, img, opt_state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     eval_pred \u001b[39m=\u001b[39m decoder(encoder(eval_batch, params), params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# eval_imgs = make_halves(eval_batch, eval_pred)\u001b[39;00m\n",
      "\u001b[1;32m/Users/syrkis/code/neuroscope/notebook.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fn\u001b[39m(params, x, opt_state):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     loss, grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvalue_and_grad(loss_fn)(params, x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     updates, opt_state \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mupdate(grads, opt_state, params)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(params, updates)\n",
      "    \u001b[0;31m[... skipping hidden 20 frame]\u001b[0m\n",
      "\u001b[1;32m/Users/syrkis/code/neuroscope/notebook.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m@jit\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_fn\u001b[39m(params, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     z \u001b[39m=\u001b[39m encoder(x, params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     x_hat \u001b[39m=\u001b[39m decoder(z, params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mmean((x \u001b[39m-\u001b[39m x_hat) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n",
      "\u001b[1;32m/Users/syrkis/code/neuroscope/notebook.ipynb Cell 11\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, (w, b) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(conv_params):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     x \u001b[39m=\u001b[39m conv(x, w, b)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mreshape(x\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], (image_size \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m (\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m depth)) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m max_channels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mdot(x, fc_params[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m fc_params[\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/syrkis/code/neuroscope/notebook.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mgelu(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:796\u001b[0m, in \u001b[0;36m_forward_method_to_aval.<locals>.meth\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmeth\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 796\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maval, name)\u001b[39m.\u001b[39;49mfun(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:145\u001b[0m, in \u001b[0;36m_reshape\u001b[0;34m(a, order, *args)\u001b[0m\n\u001b[1;32m    143\u001b[0m newshape \u001b[39m=\u001b[39m _compute_newshape(a, args[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m args)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m order \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m   \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39;49mreshape(a, newshape, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    146\u001b[0m \u001b[39melif\u001b[39;00m order \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    147\u001b[0m   dims \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(a\u001b[39m.\u001b[39mndim)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/jax/_src/core.py:1851\u001b[0m, in \u001b[0;36mDimensionHandler.divide_shape_sizes\u001b[0;34m(self, s1, s2)\u001b[0m\n\u001b[1;32m   1849\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m sz1 \u001b[39m%\u001b[39m sz2:\n\u001b[0;32m-> 1851\u001b[0m   \u001b[39mraise\u001b[39;00m InconclusiveDimensionOperation(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot divide evenly the sizes of shapes \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(s1)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(s2)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1852\u001b[0m \u001b[39mreturn\u001b[39;00m sz1 \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m sz2\n",
      "\u001b[0;31mInconclusiveDimensionOperation\u001b[0m: Cannot divide evenly the sizes of shapes (16, 27, 27, 16) and (16, 784)"
     ]
    }
   ],
   "source": [
    "train_loop(params, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
