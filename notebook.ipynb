{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "import optax\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from nilearn import plotting, datasets\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from collections import Counter\n",
    "import random\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "make_coco_metas = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/Users/syrkis/virian/projects/neuroscope'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data')\n",
    "COCO_PATH = os.path.join(DATA_DIR, 'nsd_stim_info_merged.csv')\n",
    "ANNOT_PATH = os.path.join(DATA_DIR, 'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIM = 32  # for resizing images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CAT_FILE = os.path.join(ANNOT_PATH, 'instances_train2017.json')\n",
    "VAL_CAT_FILE = os.path.join(ANNOT_PATH, 'instances_val2017.json')\n",
    "TRAIN_CAP_FILE = os.path.join(ANNOT_PATH, 'captions_train2017.json')\n",
    "VAL_CAP_FILE = os.path.join(ANNOT_PATH, 'captions_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_meta(captions_coco, instances_coco, merged_anns, nds_coco_img_ids):\n",
    "    valid_ids = set(instances_coco.getImgIds())\n",
    "    for img_id in tqdm(valid_ids):\n",
    "        anns = captions_coco.loadAnns(captions_coco.getAnnIds(imgIds=img_id))\n",
    "        captions = [ann['caption'] for ann in anns]\n",
    "        innstances = instances_coco.loadAnns(instances_coco.getAnnIds(imgIds=img_id))\n",
    "        categories = list(set([instance['category_id'] for instance in innstances]))\n",
    "        supercategory = [entry['supercategory'] for entry in instances_coco.loadCats(categories)]\n",
    "        merged_anns.append({ 'cocoId': img_id, 'captions': captions, 'categories': categories, 'supercategory': supercategory })\n",
    "    return merged_anns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_coco_metas:\n",
    "    train_instances_coco = COCO(TRAIN_CAT_FILE)\n",
    "    val_instances_coco = COCO(VAL_CAT_FILE)\n",
    "    train_captions_coco = COCO(TRAIN_CAP_FILE)\n",
    "    val_captions_coco = COCO(VAL_CAP_FILE)\n",
    "\n",
    "    merged_anns = []\n",
    "    nsd_coco = pd.read_csv(COCO_PATH)\n",
    "    nsd_coco_img_ids = set(nsd_coco['cocoId'])\n",
    "\n",
    "    valid_ids = set(val_instances_coco.getImgIds()).intersection(nsd_coco_img_ids)\n",
    "    merged_anns = extract_meta(val_captions_coco, val_instances_coco, merged_anns, nsd_coco_img_ids)\n",
    "    merged_anns = extract_meta(train_captions_coco, train_instances_coco, merged_anns, nsd_coco_img_ids)\n",
    "    df = pd.DataFrame(merged_anns)\n",
    "    df.to_csv(os.path.join(DATA_DIR, 'coco_meta_data.csv'), index=False)\n",
    "    \n",
    "    del train_instances_coco, val_instances_coco, train_captions_coco, val_captions_coco, merged_anns, nsd_coco, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_df = pd.read_csv(os.path.join(DATA_DIR, 'coco_meta_data.csv'), index_col='cocoId')\n",
    "coco_df['categories'] = coco_df['categories'].apply(lambda x: ast.literal_eval(x))\n",
    "coco_df['supercategory'] = coco_df['supercategory'].apply(lambda x: ast.literal_eval(x))\n",
    "coco_df['captions'] = coco_df['captions'].apply(lambda x: ast.literal_eval(x))\n",
    "nsd_df = pd.read_csv(os.path.join(DATA_DIR, 'nsd_stim_info_merged.csv'))\n",
    "meta_data = coco_df.loc[nsd_df['cocoId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_idxs(split):\n",
    "    if split == 'train':\n",
    "        split = 'train2017'\n",
    "    elif split == 'valid':\n",
    "        split = 'val2017'\n",
    "    mask = nsd_df['cocoSplit'] == split\n",
    "    return nsd_df[mask].index.values\n",
    "\n",
    "get_split_idxs('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(VAL_CAT_FILE)\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "cat_id_to_name = {cat['id']: cat['name'] for cat in cats}\n",
    "cat_name_to_id = {cat['name']: cat['id'] for cat in cats}\n",
    "\n",
    "# for one-hot encoding\n",
    "coco_cat_id_to_vec_index = {cat_id: i for i, cat_id in enumerate(cat_id_to_name.keys())}\n",
    "vec_index_to_coco_cat_id = {i: cat_id for i, cat_id in enumerate(cat_id_to_name.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot both validation and training histograms to confirm that they are similar\n",
    "flat_cat_list = [e for l in coco_df.loc[nsd_df.cocoId].categories.values.tolist() for e in l]\n",
    "freqs = Counter(flat_cat_list)\n",
    "#make histogram\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(freqs.keys(), freqs.values())\n",
    "x_labels = [cat_id_to_name[cat_id] for cat_id in freqs.keys()]\n",
    "plt.xticks(list(freqs.keys()), x_labels, rotation=90)\n",
    "plt.title('COCO Category Frequencies')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nsd files for particular subject\n",
    "def get_files(subject):  # can only load train data (from which valid is made). TODO: add test flag\n",
    "    lh_fmri_file = os.path.join(DATA_DIR, subject, 'training_split/training_fmri/lh_training_fmri.npy')\n",
    "    rh_fmri_file = os.path.join(DATA_DIR, subject, 'training_split/training_fmri/rh_training_fmri.npy')\n",
    "    image_dir = os.path.join(DATA_DIR, subject, 'training' + '_split', 'training' + '_images')\n",
    "    image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.png')]\n",
    "    return lh_fmri_file, rh_fmri_file, image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = image.resize((IMAGE_DIM, IMAGE_DIM))\n",
    "    image = np.array(image)\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_to_one_hot(categories):  # there are 80 categories, but the ids range from 1-90 (skipping 10) TODO: deal with this perhaps\n",
    "    one_hot = np.zeros(len(cat_id_to_name))\n",
    "    for cat in categories:\n",
    "        one_hot[coco_cat_id_to_vec_index[cat]] = 1\n",
    "    return one_hot\n",
    "\n",
    "def file_name_has_valid_coco_id(file_name, coco_ids):\n",
    "    id_from_file = file_name.split('/')[-1].split('.')[0].split('_')[-1].split('-')[-1]\n",
    "    return int(id_from_file) in coco_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batch for subject. TODO: make subject mixed batches. fmri dimensions might be subject specific.\n",
    "def get_subject_batches(subject, batch_size, n=None, split='train'):\n",
    "    _, _, image_files = get_files(subject)\n",
    "    n = n if n else len(image_files)\n",
    "    # lh, rh = np.load(lh_file), np.load(rh_file)\n",
    "    split_idxs = set(get_split_idxs(split))\n",
    "    image_files = [f for f in image_files if file_name_has_valid_coco_id(f, split_idxs)]  # I think this is right, but fuuuck\n",
    "    if n < len(image_files):\n",
    "        image_files = random.sample(image_files, n)\n",
    "    images = []\n",
    "    # look up categories for each image\n",
    "    coco_ids = [int(f.split('.')[0].split('-')[-1]) for f in image_files]\n",
    "    categories = meta_data.iloc[coco_ids]['categories'].values\n",
    "    supers = meta_data.iloc[coco_ids]['supercategory'].values\n",
    "    captions = meta_data.iloc[coco_ids]['captions'].values\n",
    "    for image_file in tqdm(image_files):\n",
    "        images.append(np.array(preprocess(Image.open(image_file))))\n",
    "    images = jnp.array(images)\n",
    "    while True:\n",
    "        perm = np.random.permutation(len(image_files))\n",
    "        for i in range(0, len(image_files), batch_size):\n",
    "            idxs = perm[i:i + batch_size]\n",
    "            # sample random category from each category list\n",
    "            cat = jnp.array([c_to_one_hot(c) for c in categories[idxs]])\n",
    "            yield images[idxs], cat, supers[idxs], captions[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_subject_batches('subj05', 16, n=100, split='train')\n",
    "valid_loader = get_subject_batches('subj05', 16, n=100, split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, cat, sup, cap = next(valid_loader)\n",
    "img, cat, sup, cap = next(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(20, 20), dpi=100)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(img[i])\n",
    "    ax.set_title(cap[i][0][:30])\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init params\n",
    "def init_mlp(layer_sizes, rng):\n",
    "    params = []\n",
    "    for n_in, n_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "        w = jax.random.normal(rng, (n_in, n_out)) * jnp.sqrt(2 / n_in)\n",
    "        b = jax.random.normal(rng, (n_out,)) * jnp.sqrt(2 / n_in)\n",
    "        params.append((w, b))\n",
    "    return params\n",
    "\n",
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def predict_mlp(params, x):\n",
    "    activations = x\n",
    "    for w, b in params:\n",
    "        outputs = jnp.dot(activations, w) + b\n",
    "        activations = relu(outputs)\n",
    "    return jax.nn.sigmoid(outputs)\n",
    "\n",
    "def loss_fn(params, x, y):\n",
    "    pred = predict_mlp(params, x)  # batch_size x image_dim\n",
    "    return -jnp.mean(y * jnp.log(pred) + (1 - y) * jnp.log(1 - pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(params, x, y):\n",
    "    pred = predict_mlp(params, x)\n",
    "    return jnp.mean((pred > 0.5) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(params, train_loader, valid_loader, metrics, steps=5):\n",
    "    # metrics is dict of lists of val loss val acc train loss train acc\n",
    "    train_loss, train_acc = [], []\n",
    "    valid_loss, valid_acc = [], []\n",
    "    for _ in range(steps):\n",
    "        x, y, _, _ = next(train_loader)\n",
    "        x = x.mean(3).reshape(x.shape[0], -1)   # TODO: this is a hack cos I'm flattening, but I don't wanna fltten\n",
    "        train_loss.append(loss_fn(params, x, y))\n",
    "        train_acc.append(accuracy(params, x, y))\n",
    "    for _ in range(steps):\n",
    "        x, y, _, _ = next(valid_loader)\n",
    "        x = x.mean(3).reshape(x.shape[0], -1)   # TODO: this is a hack cos I'm flattening, but I don't wanna fltten\n",
    "        valid_loss.append(loss_fn(params, x, y))\n",
    "        valid_acc.append(accuracy(params, x, y))\n",
    "    metrics['train_loss'].append(np.mean(train_loss))\n",
    "    metrics['train_acc'].append(np.mean(train_acc))\n",
    "    metrics['valid_loss'].append(np.mean(valid_loss))\n",
    "    metrics['valid_acc'].append(np.mean(valid_acc))\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 5), dpi=100)\n",
    "    axes[0].plot(metrics['train_loss'], label='train')\n",
    "    axes[0].plot(metrics['valid_loss'], label='valid')\n",
    "    axes[0].set_title('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(metrics['train_acc'], label='train')\n",
    "    axes[1].plot(metrics['valid_acc'], label='valid')\n",
    "    axes[1].set_title('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_subject_batches('subj05', 16, n=1000)\n",
    "valid_loader = get_subject_batches('subj05', 16, n=100, split='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "params = init_mlp([IMAGE_DIM ** 2, 512, 512, 80], rng)\n",
    "metrics = {'train_loss': [], 'train_acc': [], 'valid_loss': [], 'valid_acc': []}\n",
    "optimizer = optax.adam(1e-4)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(params, x, y, opt, opt_state):\n",
    "    grads = grad(loss_fn)(params, x, y)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 500\n",
    "pbar = tqdm(range(steps))\n",
    "for i in pbar:\n",
    "    image, cats, supers, caps = next(train_loader)\n",
    "    image = image.mean(3).reshape(-1, IMAGE_DIM ** 2)\n",
    "    params, opt_state = update(params, image, cats, opt_state)\n",
    "    if i % (steps // 50) == 0:\n",
    "        metrics = evaluate(params, train_loader, valid_loader, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
