{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import torch\n",
    "from torchvision.models import alexnet\n",
    "from src.utils import get_args_and_config\n",
    "from src.data import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:08<00:00, 121.17it/s]\n",
      "2023-05-26 11:19:07.453919: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:427] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# batched alexnet\u001b[39;00m\n\u001b[1;32m      2\u001b[0m args, config \u001b[39m=\u001b[39m get_args_and_config()\n\u001b[0;32m----> 3\u001b[0m data \u001b[39m=\u001b[39m get_data(args, config)\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m alexnet(weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# deal with warnings later\u001b[39;00m\n",
      "File \u001b[0;32m~/neuroscope/src/data.py:28\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(args, config)\u001b[0m\n\u001b[1;32m     26\u001b[0m train_idxs, test_idxs \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(jnp\u001b[39m.\u001b[39marray, train_test_split(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(images)), test_size\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m))\n\u001b[1;32m     27\u001b[0m train_img_files \u001b[39m=\u001b[39m [img_files[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m train_idxs\u001b[39m.\u001b[39mtolist()]\n\u001b[0;32m---> 28\u001b[0m folds \u001b[39m=\u001b[39m get_folds(images[train_idxs], args, meta_data, train_img_files, subject, k\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mk_folds\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     30\u001b[0m test_img_files \u001b[39m=\u001b[39m [img_files[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m test_idxs\u001b[39m.\u001b[39mtolist()]\n\u001b[1;32m     31\u001b[0m test_data \u001b[39m=\u001b[39m get_subject_data(images[test_idxs], args, meta_data, test_img_files, subject)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/array.py:316\u001b[0m, in \u001b[0;36mArrayImpl.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    314\u001b[0m   \u001b[39mreturn\u001b[39;00m lax_numpy\u001b[39m.\u001b[39m_rewriting_take(\u001b[39mself\u001b[39m, idx)\n\u001b[1;32m    315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m   \u001b[39mreturn\u001b[39;00m lax_numpy\u001b[39m.\u001b[39;49m_rewriting_take(\u001b[39mself\u001b[39;49m, idx)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py:4092\u001b[0m, in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4089\u001b[0m       \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   4091\u001b[0m treedef, static_idx, dynamic_idx \u001b[39m=\u001b[39m _split_index_for_jit(idx, arr\u001b[39m.\u001b[39mshape)\n\u001b[0;32m-> 4092\u001b[0m \u001b[39mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4093\u001b[0m                unique_indices, mode, fill_value)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py:4101\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value)\u001b[0m\n\u001b[1;32m   4098\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m   4099\u001b[0m             unique_indices, mode, fill_value):\n\u001b[1;32m   4100\u001b[0m   idx \u001b[39m=\u001b[39m _merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[0;32m-> 4101\u001b[0m   indexer \u001b[39m=\u001b[39m _index_to_gather(shape(arr), idx)  \u001b[39m# shared with _scatter_update\u001b[39;00m\n\u001b[1;32m   4102\u001b[0m   y \u001b[39m=\u001b[39m arr\n\u001b[1;32m   4104\u001b[0m   \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py:4228\u001b[0m, in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   4225\u001b[0m   \u001b[39mif\u001b[39;00m normalize_indices:\n\u001b[1;32m   4226\u001b[0m     advanced_pairs \u001b[39m=\u001b[39m ((_normalize_index(e, x_shape[j]), i, j)\n\u001b[1;32m   4227\u001b[0m                       \u001b[39mfor\u001b[39;00m e, i, j \u001b[39min\u001b[39;00m advanced_pairs)\n\u001b[0;32m-> 4228\u001b[0m   advanced_indexes, idx_advanced_axes, x_advanced_axes \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49madvanced_pairs)\n\u001b[1;32m   4229\u001b[0m   advanced_axes_are_contiguous \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39mdiff(idx_advanced_axes) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m   4231\u001b[0m x_axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Current axis in x.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py:4226\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4222\u001b[0m advanced_pairs \u001b[39m=\u001b[39m (\n\u001b[1;32m   4223\u001b[0m   (asarray(e), i, j) \u001b[39mfor\u001b[39;00m j, (i, e) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(idx_no_nones)\n\u001b[1;32m   4224\u001b[0m   \u001b[39mif\u001b[39;00m isscalar(e) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(e, (Sequence, Array, np\u001b[39m.\u001b[39mndarray)))\n\u001b[1;32m   4225\u001b[0m \u001b[39mif\u001b[39;00m normalize_indices:\n\u001b[0;32m-> 4226\u001b[0m   advanced_pairs \u001b[39m=\u001b[39m ((_normalize_index(e, x_shape[j]), i, j)\n\u001b[1;32m   4227\u001b[0m                     \u001b[39mfor\u001b[39;00m e, i, j \u001b[39min\u001b[39;00m advanced_pairs)\n\u001b[1;32m   4228\u001b[0m advanced_indexes, idx_advanced_axes, x_advanced_axes \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39madvanced_pairs)\n\u001b[1;32m   4229\u001b[0m advanced_axes_are_contiguous \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39mdiff(idx_advanced_axes) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py:3876\u001b[0m, in \u001b[0;36m_normalize_index\u001b[0;34m(index, axis_size)\u001b[0m\n\u001b[1;32m   3874\u001b[0m   \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39madd(index, axis_size_val) \u001b[39mif\u001b[39;00m index \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m index\n\u001b[1;32m   3875\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3876\u001b[0m   \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mselect(index \u001b[39m<\u001b[39;49m \u001b[39m0\u001b[39;49m, lax\u001b[39m.\u001b[39madd(index, axis_size_val), index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/array_methods.py:258\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    256\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 258\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _rejected_binop_types):\n\u001b[1;32m    260\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsupported operand type(s) for \u001b[39m\u001b[39m{\u001b[39;00mopchar\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(args[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(args[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/dispatch.py:463\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    459\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    460\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details."
     ]
    }
   ],
   "source": [
    "# batched alexnet\n",
    "args, config = get_args_and_config()\n",
    "data = get_data(args, config)\n",
    "model = alexnet(weights=True)  # deal with warnings later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
