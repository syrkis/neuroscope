{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroscape playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import src\n",
    "import jax\n",
    "from jax import random, grad, jit, vmap, lax\n",
    "import jax.numpy as jnp\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import datasets, plotting, maskers\n",
    "from tqdm import tqdm\n",
    "# black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(src);\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "batch_size = 32\n",
    "n_samples = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args_list = [\n",
    "    '--model', 'fmri2cat',\n",
    "    '--roi', 'V1d',\n",
    "    '--machine', 'local',\n",
    "    '--subject', 'subj05',\n",
    "    '--batch_size', str(batch_size),\n",
    "    '--n_samples', str(n_samples),\n",
    "    '--n_steps', str(n_steps),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_data = True  # flip to false after first run\n",
    "config, args = src.get_setup(args_list)\n",
    "if reload_data:\n",
    "    train_loader, val_loader, _ = src.get_loaders(args, config)\n",
    "    next(train_loader), next(val_loader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "layer_sizes = [rh.shape[-1] + lh.shape[-1], 128, 128, 80]\n",
    "params = src.model.init_mlp(layer_sizes, rng)\n",
    "metrics = {'train_f1': [], 'val_f1': [], 'train_loss': [], 'val_loss': [], 'baseline_f1': [], 'baseline_loss': []}\n",
    "freqs, n = np.zeros(80), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, x, y, pred=None):\n",
    "    pred = src.model.forward_mlp(params, x) if pred is None else pred\n",
    "    return -jnp.mean(y * jnp.log(pred) + (1 - y) * jnp.log(1 - pred))\n",
    "\n",
    "def f1_score(params, x, y, pred=None):\n",
    "    pred = src.model.forward_mlp(params, x) if pred is None else pred\n",
    "    pred = pred > 0.5\n",
    "    tp = jnp.sum(pred * y)\n",
    "    fp = jnp.sum(pred * (1 - y))\n",
    "    fn = jnp.sum((1 - pred) * y)\n",
    "    return tp / (tp + 0.5 * (fp + fn))\n",
    "\n",
    "def baseline(params, x, y, probs):\n",
    "    pred = np.random.rand(*y.shape) < probs\n",
    "    loss = loss_fn(params, x, y, pred)\n",
    "    f1 = f1_score(params, x, y, pred)\n",
    "    return loss, f1\n",
    "\n",
    "\n",
    "grad_fn = jit(grad(loss_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 4000\n",
    "for i in tqdm(range(steps)):\n",
    "    img, cat, sup, cap, lh, rh = next(train_loader)\n",
    "    lrh = np.concatenate([rh, lh], axis=-1)\n",
    "    freqs, n = freqs + np.sum(cat, axis=0), n + cat.shape[0]\n",
    "    val_img, val_cat, val_sup, val_cap, val_lh, val_rh = next(val_loader)\n",
    "    val_lrh = np.concatenate([val_rh, val_lh], axis=-1)\n",
    "    pred = src.model.forward_mlp(params, lrh)\n",
    "    grads = grad_fn(params, lrh, cat)\n",
    "    params = [(w - 0.01 * dw, b - 0.01 * db) for (w, b), (dw, db) in zip(params, grads)]\n",
    "    loss = loss_fn(params, lrh, cat)\n",
    "    f1 = f1_score(params, lrh, cat)\n",
    "    val_loss = loss_fn(params, val_lrh, val_cat)\n",
    "    val_f1 = f1_score(params, val_lrh, val_cat)\n",
    "    baseline_loss, baseline_f1 = baseline(params, lrh, cat, freqs / n)\n",
    "    metrics['baseline_f1'].append(baseline_f1)\n",
    "    metrics['baseline_loss'].append(baseline_loss)\n",
    "    metrics['train_f1'].append(f1)\n",
    "    metrics['val_f1'].append(val_f1)\n",
    "    metrics['train_loss'].append(loss)\n",
    "    metrics['val_loss'].append(val_loss)\n",
    "\n",
    "\n",
    "\n",
    "# src.plot_metrics(metrics);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rolling_average = lambda lst: [np.mean(lst[i:i+30]) for i in range(len(lst) - 30)]\n",
    "\n",
    "# params, metrics = src.train(params, metrics, config, args, train_loader, val_loader)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5), dpi=100)\n",
    "axes[0].plot(rolling_average(metrics['train_loss']), label='train')\n",
    "axes[0].plot(rolling_average(metrics['val_loss']), label='val')\n",
    "axes[0].plot(rolling_average(metrics['baseline_loss']), label='baseline')\n",
    "axes[0].set_title('Binary Cross Entropy Loss')\n",
    "axes[0].legend()\n",
    "axes[1].plot(rolling_average(metrics['train_f1']), label='train')\n",
    "axes[1].plot(rolling_average(metrics['val_f1']), label='val')\n",
    "axes[1].plot(rolling_average(metrics['baseline_f1']), label='baseline')\n",
    "axes[1].set_title('F1 Score')\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sizes = [p.size for p in jax.tree_util.tree_flatten(params)[0]]\n",
    "num_params = sum(param_sizes)\n",
    "print(f'Number of parameters: {num_params}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learn haiku"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
