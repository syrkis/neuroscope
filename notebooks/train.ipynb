{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroscape playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import haiku as hk\n",
    "import optax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, vmap, lax\n",
    "import sys; sys.path.append(\"..\")\n",
    "import src\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "# black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use('dark_background')\n",
    "jax.devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 5000\n",
    "batch_size = 32\n",
    "n_samples = 2 ** 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args_list = [\n",
    "    '--model', 'fmri2cat',\n",
    "    '--roi', 'V1d,V1v',\n",
    "    '--machine', 'local',\n",
    "    '--subject', 'subj05',\n",
    "    '--batch_size', str(batch_size),\n",
    "    '--n_samples', str(n_samples),\n",
    "    '--n_steps', str(n_steps),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "--roi must be one of ['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4', 'EBA', 'FBA-1', 'FBA-2', 'mTL-bodies', 'OFA', 'FFA-1', 'FFA-2', 'mTL-faces', 'aTL-faces', 'OPA', 'PPA', 'RSC', 'OWFA', 'VWFA-1', 'VWFA-2', 'mfs-words', 'mTL-words', 'early', 'midventral', 'midlateral', 'midparietal', 'ventral', 'lateral', 'parietal']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m config, args \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39;49mget_setup(args_list)\n\u001b[1;32m      2\u001b[0m \u001b[39m# if variable called lh not in scope\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mlh\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mlocals\u001b[39m():\n",
      "File \u001b[0;32m~/neuroscope/src/utils.py:86\u001b[0m, in \u001b[0;36mget_setup\u001b[0;34m(args_list)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_setup\u001b[39m(args_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 86\u001b[0m     args \u001b[39m=\u001b[39m get_args(args_list)\n\u001b[1;32m     87\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DIR, \u001b[39m'\u001b[39m\u001b[39mconfig.yaml\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     88\u001b[0m         config \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39mload(f, Loader\u001b[39m=\u001b[39myaml\u001b[39m.\u001b[39mFullLoader)\n",
      "File \u001b[0;32m~/neuroscope/src/utils.py:80\u001b[0m, in \u001b[0;36mget_args\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     78\u001b[0m args \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mparse_args(args)\n\u001b[1;32m     79\u001b[0m \u001b[39massert\u001b[39;00m args\u001b[39m.\u001b[39mmodel \u001b[39min\u001b[39;00m models, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--model must be one of \u001b[39m\u001b[39m{\u001b[39;00mmodels\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 80\u001b[0m \u001b[39massert\u001b[39;00m args\u001b[39m.\u001b[39mroi \u001b[39min\u001b[39;00m rois, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--roi must be one of \u001b[39m\u001b[39m{\u001b[39;00mrois\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m args\n",
      "\u001b[0;31mAssertionError\u001b[0m: --roi must be one of ['V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4', 'EBA', 'FBA-1', 'FBA-2', 'mTL-bodies', 'OFA', 'FFA-1', 'FFA-2', 'mTL-faces', 'aTL-faces', 'OPA', 'PPA', 'RSC', 'OWFA', 'VWFA-1', 'VWFA-2', 'mfs-words', 'mTL-words', 'early', 'midventral', 'midlateral', 'midparietal', 'ventral', 'lateral', 'parietal']"
     ]
    }
   ],
   "source": [
    "config, args = src.get_setup(args_list)\n",
    "# if variable called lh not in scope\n",
    "if 'lh' not in locals():\n",
    "    train_loader, val_loader, _ = src.get_loaders(args, config)\n",
    "    img, cat, sup, cap, lh, rh =  next(train_loader)\n",
    "    img, cat, sup, cap, lh, rh =  next(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(train_loader, steps=n_samples // batch_size):\n",
    "    \"\"\"Compute the target distribution for the training data.\"\"\"\n",
    "    _, cat, _, _, _, _ = next(train_loader)\n",
    "    freqs = jnp.zeros_like(cat[0])\n",
    "    for _ in tqdm(range(steps)):\n",
    "        _, cat, _, _, _, _ = next(train_loader)\n",
    "        freqs += jnp.sum(cat, axis=0)\n",
    "    probs = freqs / (steps * batch_size)\n",
    "    return probs\n",
    "\n",
    "def plot_metrics(metrics):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5), dpi=100)\n",
    "    for k, v in metrics.items():\n",
    "        if k.endswith('loss'):\n",
    "            axes[0].plot(v, label=k[:-5])\n",
    "        if k.endswith('f1'):\n",
    "            axes[1].plot(v, label=k[:-3])\n",
    "    axes[0].set_title('loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].set_title('f1')\n",
    "    axes[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_fn(x):\n",
    "    mlp = hk.Sequential([\n",
    "        hk.Linear(128), jax.nn.gelu,\n",
    "        hk.Linear(128), jax.nn.gelu,\n",
    "        hk.Linear(128), jax.nn.gelu,\n",
    "        hk.Linear(80), jax.nn.sigmoid,\n",
    "    ])\n",
    "    return mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m init, forward \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39mwithout_apply_rng(hk\u001b[39m.\u001b[39mtransform(network_fn))\n\u001b[1;32m      2\u001b[0m scheduler \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mcosine_decay_schedule(\u001b[39m1e-3\u001b[39m, n_steps, \u001b[39m1e-5\u001b[39m)\n\u001b[1;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39madam(scheduler)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'network_fn' is not defined"
     ]
    }
   ],
   "source": [
    "init, forward = hk.without_apply_rng(hk.transform(network_fn))\n",
    "scheduler = optax.cosine_decay_schedule(1e-3, n_steps, 1e-5)\n",
    "optimizer = optax.adam(scheduler)\n",
    "probs = target_distribution(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state):\n",
    "    grads = grad(loss_fn)(params, x, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "def f1_score(params, x, y, pred=None):\n",
    "    pred = forward(params, x) > 0.5 if pred is None else pred\n",
    "    pred, y = pred.astype('int32'), y.astype('int32')\n",
    "    tp = jnp.sum(pred * y)\n",
    "    fp = jnp.sum(pred * (1 - y))\n",
    "    fn = jnp.sum((1 - pred) * y)\n",
    "    return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "def loss_fn(params, x, y, pred=None):\n",
    "    # soft f1 loss (account for base line with 0's and 1's)\n",
    "    pred = forward(params, x) if pred is None else pred\n",
    "    tp = jnp.sum(pred * y)\n",
    "    fp = jnp.sum(pred * (1 - y))\n",
    "    fn = jnp.sum((1 - pred) * y)\n",
    "    return 1 - (2 * tp) / (2 * tp + fp + fn)\n",
    "\n",
    "\n",
    "def baseline(params, x, y, probs, rng):\n",
    "    pred = random.uniform(next(rng), (x.shape[0], 80)) < probs\n",
    "    loss = loss_fn(params, x, y, pred)\n",
    "    f1 = f1_score(params, x, y, pred)\n",
    "    return loss, f1\n",
    "\n",
    "def evaluate(params, train_loader, val_loader, probs, rng, steps=20):\n",
    "    train_loss, train_f1, val_loss, val_f1, base_loss, base_f1 = [], [], [], [], [], []\n",
    "    for _ in range(steps):\n",
    "        _, y, _, _, lh, rh = next(train_loader)       # training\n",
    "        x = jnp.concatenate([lh, rh], axis=1)\n",
    "        train_loss.append(loss_fn(params, x, y))\n",
    "        train_f1.append(f1_score(params, x, y))\n",
    "        _, val_y, _, _, val_lh, val_rh = next(val_loader)         # validation\n",
    "        val_x = jnp.concatenate([val_lh, val_rh], axis=1)\n",
    "        val_loss.append(loss_fn(params, val_x, val_y))\n",
    "        val_f1.append(f1_score(params, val_x, val_y))\n",
    "        b_loss, b_f1 = baseline(params, val_x, val_y, probs, rng) # baseline\n",
    "        base_loss.append(b_loss)\n",
    "        base_f1.append(b_f1)\n",
    "    return dict(\n",
    "        train_loss=np.mean(train_loss),\n",
    "        train_f1=np.mean(train_f1),\n",
    "        val_loss=np.mean(val_loss),\n",
    "        val_f1=np.mean(val_f1),\n",
    "        base_loss=np.mean(base_loss),\n",
    "        base_f1=np.mean(base_f1),\n",
    "    )\n",
    "\n",
    "def train(params, state, train_loader, val_loader, probs, rng, steps=n_steps):\n",
    "    wandb.init(project='neuroscope', entity='syrkis', config=args)\n",
    "    for step in tqdm(range(steps)):\n",
    "        _, y, _, _, lh, rh = next(train_loader)\n",
    "        x = jnp.concatenate([lh, rh], axis=1)\n",
    "        params, state = update(params, x, y, state)\n",
    "        if step % (steps // 100) == 0:\n",
    "            wandb.log(evaluate(params, train_loader, val_loader, probs, rng))\n",
    "    wandb.finish()\n",
    "    return params, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msyrkis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nobr/neuroscope/wandb/run-20230516_193911-gkdk47az</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/syrkis/neuroscope/runs/gkdk47az' target=\"_blank\">radiant-sun-15</a></strong> to <a href='https://wandb.ai/syrkis/neuroscope' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/syrkis/neuroscope' target=\"_blank\">https://wandb.ai/syrkis/neuroscope</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/syrkis/neuroscope/runs/gkdk47az' target=\"_blank\">https://wandb.ai/syrkis/neuroscope/runs/gkdk47az</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:05<00:00, 27.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>base_f1</td><td>▆▃▄▃▄█▅▆▅▄▁▆▆▆▂▄▄▆▆▂▆▅▂▇▆▂▃▁▃▆▄▅▂▃▄▆▅▅▅▄</td></tr><tr><td>base_loss</td><td>▃▆▅▆▅▁▄▃▄▅█▃▃▃▇▅▅▃▃▇▃▄▇▂▃▇▆█▆▃▅▄▇▆▅▃▄▄▄▅</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▇▆▆▆▆▆▆▆▆▆▆▇▆▇████████</td></tr><tr><td>train_loss</td><td>█▃▃▃▃▃▃▃▃▃▃▃▃▂▃▃▂▂▂▃▃▃▃▃▃▃▃▃▃▂▃▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▅▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▇▇█▇█▇█▇█</td></tr><tr><td>val_loss</td><td>█▄▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▁▂▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>base_f1</td><td>0.11904</td></tr><tr><td>base_loss</td><td>0.88096</td></tr><tr><td>train_f1</td><td>0.25327</td></tr><tr><td>train_loss</td><td>0.74662</td></tr><tr><td>val_f1</td><td>0.28392</td></tr><tr><td>val_loss</td><td>0.71612</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sun-15</strong> at: <a href='https://wandb.ai/syrkis/neuroscope/runs/gkdk47az' target=\"_blank\">https://wandb.ai/syrkis/neuroscope/runs/gkdk47az</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230516_193911-gkdk47az/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "params = init(next(rng), jnp.concatenate([lh, rh], axis=1))\n",
    "state = optimizer.init(params)\n",
    "params, state = train(params, state, train_loader, val_loader, probs, rng)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
