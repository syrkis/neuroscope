{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroscape playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "from jax.tree_util import tree_map\n",
    "from jax import pmap, vmap, grad, jit\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict, Generator\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from functools import partial\n",
    "from src.train import update, evaluate\n",
    "from src.model import init, forward, loss_fn, network_fn\n",
    "from src.utils import get_setup\n",
    "from src.data import get_loaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "batch_size = 4\n",
    "n_samples = 1024\n",
    "image_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = [\n",
    "    \"--roi\", \"V1v,V2v\",\n",
    "    \"--subject\", \"subj05\",\n",
    "    \"--batch_size\", str(batch_size),\n",
    "    \"--n_samples\", str(n_samples),\n",
    "    \"--n_steps\", str(n_steps),\n",
    "    \"--image_size\", str(image_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:07<00:00, 142.56it/s]\n"
     ]
    }
   ],
   "source": [
    "opt = optax.adam(1e-3)\n",
    "cli_args, config = get_setup(args_list)\n",
    "folds, _ = get_loaders(cli_args, config)\n",
    "config['batch_size'] = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msyrkis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nobr/neuroscope/wandb/run-20230522_090636-iu717bjr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/syrkis/neuroscope/runs/iu717bjr' target=\"_blank\">hardy-galaxy-95</a></strong> to <a href='https://wandb.ai/syrkis/neuroscope' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/syrkis/neuroscope' target=\"_blank\">https://wandb.ai/syrkis/neuroscope</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/syrkis/neuroscope/runs/iu717bjr' target=\"_blank\">https://wandb.ai/syrkis/neuroscope/runs/iu717bjr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "network_fn() missing 1 required positional argument: 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m     new_params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(params, updates)\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m new_params, opt_state\n\u001b[0;32m---> 59\u001b[0m params_lst \u001b[39m=\u001b[39m train(folds, config)\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(folds, config)\u001b[0m\n\u001b[1;32m     15\u001b[0m train_fold \u001b[39m=\u001b[39m partial(train_fold_fn, config\u001b[39m=\u001b[39mconfig)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m idx, (params, fold) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(params_lst, folds_lst)):\n\u001b[0;32m---> 17\u001b[0m     params_lst[idx] \u001b[39m=\u001b[39m train_fold(params, fold)\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m params_lst\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mtrain_fold_fn\u001b[0;34m(params, fold, config)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config[\u001b[39m'\u001b[39m\u001b[39mn_steps\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m     27\u001b[0m     img, cat, fmri \u001b[39m=\u001b[39m get_batch(train_data, config[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 28\u001b[0m     params, opt_state \u001b[39m=\u001b[39m update(params, img, cat, fmri, opt_state)\n\u001b[1;32m     29\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m (config[\u001b[39m'\u001b[39m\u001b[39mn_steps\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m         metrics \u001b[39m=\u001b[39m evaluate(params, train_data, val_data, get_batch)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[6], line 54\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(params, img, cat, fmri, opt_state)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m@jit\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(params: hk\u001b[39m.\u001b[39mParams, img: jnp\u001b[39m.\u001b[39mndarray, cat: jnp\u001b[39m.\u001b[39mndarray, fmri: jnp\u001b[39m.\u001b[39mndarray, opt_state: optax\u001b[39m.\u001b[39mOptState) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[hk\u001b[39m.\u001b[39mParams, optax\u001b[39m.\u001b[39mOptState]:\n\u001b[0;32m---> 54\u001b[0m     grads \u001b[39m=\u001b[39m grad(loss_fn)(params, img, cat, fmri)\n\u001b[1;32m     55\u001b[0m     updates, opt_state \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mupdate(grads, opt_state)\n\u001b[1;32m     56\u001b[0m     new_params \u001b[39m=\u001b[39m optax\u001b[39m.\u001b[39mapply_updates(params, updates)\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "File \u001b[0;32m~/neuroscope/src/model.py:50\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(params, img, cat, fmri)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_fn\u001b[39m(params, img, cat, fmri):\n\u001b[1;32m     49\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"loss function\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     pred \u001b[39m=\u001b[39m forward(params, img, cat)\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mmean((pred \u001b[39m-\u001b[39m fmri) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/multi_transform.py:298\u001b[0m, in \u001b[0;36mwithout_apply_rng.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m(params, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    297\u001b[0m   check_rng_kwarg(kwargs)\n\u001b[0;32m--> 298\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mapply(params, \u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/transform.py:128\u001b[0m, in \u001b[0;36mwithout_state.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    122\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    123\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mHaiku transform adds three arguments (params, state, rng) to apply. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mIf the functions you are transforming use the same names you must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mpass them positionally (e.g. `f.apply(.., my_state)` and not by \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mname (e.g. `f.apply(.., state=my_state)`)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m out, state \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mapply(params, {}, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m    130\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf your transformed function uses `hk.\u001b[39m\u001b[39m{\u001b[39m\u001b[39mget,set}_state` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mthen use `hk.transform_with_state`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/transform.py:357\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(params\u001b[39m=\u001b[39mparams, state\u001b[39m=\u001b[39mstate, rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    356\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     out \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    358\u001b[0m   \u001b[39mexcept\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    359\u001b[0m     \u001b[39mraise\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: network_fn() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "source": [
    "\n",
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# types\n",
    "Fold = Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]\n",
    "Batch = Fold\n",
    "\n",
    "\n",
    "# functions\n",
    "def train(folds: List[Fold], config: Dict) -> List[hk.Params]:\n",
    "    \"\"\"train function\"\"\"\n",
    "    # TODO: parallelize using pmap or vmap\n",
    "    config['group_name'] = wandb.util.generate_id()\n",
    "    folds_lst = [make_fold(folds, fold) for fold in range(len(folds))]  # (train_data, val_data) list\n",
    "    params_lst = [init(next(rng), folds[0][0], folds[0][1]) for _ in range(len(folds))]\n",
    "    train_fold = partial(train_fold_fn, config=config)\n",
    "    for idx, (params, fold) in enumerate(zip(params_lst, folds_lst)):\n",
    "        params_lst[idx] = train_fold(params, fold)\n",
    "    return params_lst\n",
    "\n",
    "\n",
    "def train_fold_fn(params, fold, config: Dict) -> hk.Params:\n",
    "    \"\"\"train_fold function\"\"\"\n",
    "    train_data, val_data = fold\n",
    "    wandb.init(project=\"neuroscope\", entity='syrkis', config=config, group=config['group_name'])\n",
    "    opt_state = opt.init(params)\n",
    "    for step in range(config['n_steps']):\n",
    "        img, cat, fmri = get_batch(train_data, config['batch_size'])\n",
    "        params, opt_state = update(params, img, cat, fmri, opt_state)\n",
    "        if step % (config['n_steps'] // 100) == 0:\n",
    "            metrics = evaluate(params, train_data, val_data, get_batch)\n",
    "            wandb.log(metrics, step=step)\n",
    "    wandb.finish()\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_batch(fold: Fold, batch_size: int) -> Batch:\n",
    "    \"\"\"get a batch from a split\"\"\"\n",
    "    img, cat, fmri = fold\n",
    "    idx = np.random.randint(0, img.shape[0], batch_size)\n",
    "    return img[idx], cat[idx], fmri[idx]\n",
    "\n",
    "\n",
    "def make_fold(folds: List[Fold], fold: int) -> Batch:\n",
    "    \"\"\"make a fold from a list of folds\"\"\"\n",
    "    train_imgs = [f[0] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_cats = [f[1] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_fmris = [f[2] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_data = tuple(map(jnp.concatenate, [train_imgs, train_cats, train_fmris]))\n",
    "    return train_data, folds[fold]\n",
    "\n",
    "\n",
    "@jit\n",
    "def update(params: hk.Params, img: jnp.ndarray, cat: jnp.ndarray, fmri: jnp.ndarray, opt_state: optax.OptState) -> Tuple[hk.Params, optax.OptState]:\n",
    "    grads = grad(loss_fn)(params, img, cat, fmri)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "params_lst = train(folds, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
