{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroscape playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import grad, jit\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "import optax\n",
    "import wandb\n",
    "from typing import List, Tuple, Dict\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from src.model import lh_init, rh_init, loss_fns\n",
    "from src.eval import evaluate\n",
    "from src.data import get_data\n",
    "from src.utils import get_args_and_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold = Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]\n",
    "Batch = Fold\n",
    "lh_train_loss_fn, rh_train_loss_fn = loss_fns['lh']\n",
    "lh_infer_loss_fn, rh_infer_loss_fn = loss_fns['rh']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optax.adam(1e-3)\n",
    "args, config = get_args_and_config()\n",
    "data = get_data(args, config)\n",
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def train(data, config):\n",
    "    \"\"\"train function\"\"\"\n",
    "    config['group_name'] = wandb.util.generate_id()\n",
    "    for subject, (folds, _) in data.items():\n",
    "        lh_params_lst, rh_params_lst = train_subject(folds, config)\n",
    "        np.save(f'results/models/{subject}_lh.npy', lh_params_lst)\n",
    "        np.save(f'results/models/{subject}_rh.npy', rh_params_lst)\n",
    "\n",
    "\n",
    "def train_subject(folds: List[Fold], config: Dict) -> Tuple[List[hk.Params], List[hk.Params]]:\n",
    "    \"\"\"train function\"\"\"\n",
    "    # TODO: parallelize using pmap or vmap\n",
    "    data = [make_fold(folds, fold) for fold in range(len(folds))]  # (train_data, val_data) list\n",
    "    train_fold = partial(train_fold_fn, config=config)\n",
    "    lh_params_lst, rh_params_lst = [], []\n",
    "    for hem, init_fn in zip(['lh', 'rh'], [lh_init, rh_init]):\n",
    "        config['hem'] = hem\n",
    "        train_loss_fn, val_loss_fn = loss_fns(hem)\n",
    "        params_lst = [init_fn(next(rng), img) for img, _, _, _ in folds]\n",
    "        for idx, (params, fold) in enumerate(zip(params_lst, data)):\n",
    "            params = train_fold(params, fold, train_loss_fn, val_loss_fn)\n",
    "            params_lst[idx] = params\n",
    "        if hem == 'lh':\n",
    "            lh_params_lst = params_lst\n",
    "        else:\n",
    "            rh_params_lst = params_lst\n",
    "    return lh_params_lst, rh_params_lst\n",
    "\n",
    "\n",
    "def train_fold_fn(params, fold, config: Dict, train_loss_fn, val_loss_fn, hem) -> hk.Params:\n",
    "    \"\"\"train_fold function\"\"\"\n",
    "    train_data, val_data = fold\n",
    "    wandb.init(project=\"neuroscope\", entity='syrkis', config=config, group=config['group_name'])\n",
    "    for step in tqdm(range(config['n_steps'])):\n",
    "        batch = get_batch(train_data, config['batch_size'])\n",
    "        params, opt_state = lh_update(params, batch, opt_state) if hem == 'lh' else rh_update(params, batch, opt_state)\n",
    "        if step % (config['n_steps'] // 100) == 0:\n",
    "            metrics = evaluate(params, train_data, val_data, get_batch, config, train_loss_fn, val_loss_fn)\n",
    "            wandb.log(metrics, step=step)\n",
    "    wandb.finish()\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_batch(fold: Fold, batch_size: int, hem: str) -> Batch:\n",
    "    \"\"\"get a batch from a split\"\"\"\n",
    "    img, cat, lh, rh = fold\n",
    "    idx = np.random.randint(0, img.shape[0], batch_size)\n",
    "    fmri = lh if hem == 'lh' else rh\n",
    "    return img[idx], cat[idx], fmri[idx]\n",
    "\n",
    "\n",
    "def make_fold(folds: List[Fold], fold: int) -> Batch:\n",
    "    \"\"\"make a fold from a list of folds\"\"\"\n",
    "    train_imgs = [f[0] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_cats = [f[1] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_fmris = [f[2] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_data = tuple(map(jnp.concatenate, [train_imgs, train_cats, train_fmris]))\n",
    "    return train_data, folds[fold]\n",
    "\n",
    "\n",
    "def lh_update(params: hk.Params, batch: Batch, opt_state: optax.OptState) -> Tuple[hk.Params, optax.OptState]:\n",
    "    grads = grad(lh_train_loss_fn)(params, batch)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "def rh_update(params: hk.Params, batch: Batch, opt_state: optax.OptState) -> Tuple[hk.Params, optax.OptState]:\n",
    "    grads = grad(rh_train_loss_fn)(params, batch)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
