{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroscape playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import haiku as hk\n",
    "import optax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import src\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"dark_background\")\n",
    "jax.devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 3000\n",
    "batch_size = 32\n",
    "n_samples = 2**13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = [\n",
    "    \"--model\",\n",
    "    \"fmri2cat\",\n",
    "    \"--roi\",\n",
    "    \"V1v,V1d\",\n",
    "    \"--machine\",\n",
    "    \"local\",\n",
    "    \"--subject\",\n",
    "    \"subj05\",\n",
    "    \"--batch_size\",\n",
    "    str(batch_size),\n",
    "    \"--n_samples\",\n",
    "    str(n_samples),\n",
    "    \"--n_steps\",\n",
    "    str(n_steps),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args, config = src.get_setup(args_list)\n",
    "# if variable called lh not in scope\n",
    "if \"lh\" not in locals():\n",
    "    train_loader, val_loader, _ = src.get_loaders(args, config)\n",
    "    img, cat, sup, cap, lh, rh = next(train_loader)\n",
    "    img, cat, sup, cap, lh, rh = next(val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(train_loader, steps=n_samples // batch_size):\n",
    "    \"\"\"Compute the target distribution for the training data.\"\"\"\n",
    "    _, cat, _, _, _, _ = next(train_loader)\n",
    "    freqs = jnp.zeros_like(cat[0])\n",
    "    for _ in tqdm(range(steps)):\n",
    "        _, cat, _, _, _, _ = next(train_loader)\n",
    "        freqs += jnp.sum(cat, axis=0)\n",
    "    probs = freqs / (steps * batch_size)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def plot_metrics(metrics):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5), dpi=100)\n",
    "    for k, v in metrics.items():\n",
    "        if k.endswith(\"loss\"):\n",
    "            axes[0].plot(v, label=k[:-5])\n",
    "        if k.endswith(\"f1\"):\n",
    "            axes[1].plot(v, label=k[:-3])\n",
    "    axes[0].set_title(\"loss\")\n",
    "    axes[0].legend()\n",
    "    axes[1].set_title(\"f1\")\n",
    "    axes[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = hk.Sequential(\n",
    "    [\n",
    "        hk.Flatten(),\n",
    "        hk.Linear(512),\n",
    "        jax.nn.relu,\n",
    "        hk.Linear(512),\n",
    "        jax.nn.relu,\n",
    "        hk.Linear(80),\n",
    "        jax.nn.sigmoid,\n",
    "    ]\n",
    ")\n",
    "\n",
    "deconv = hk.Sequential(\n",
    "    [\n",
    "        hk.Conv2D(32, kernel_shape=3, padding=\"SAME\"),\n",
    "        jax.nn.relu,\n",
    "        hk.Conv2DTranspose(32, kernel_shape=3, padding=\"SAME\"),\n",
    "        jax.nn.relu,\n",
    "        hk.Conv2DTranspose(3, kernel_shape=3, padding=\"SAME\"),\n",
    "        jax.nn.sigmoid,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_fn(x):\n",
    "    z = mlp(x)\n",
    "    z = z.reshape((batch_size, 32, 32, 1))\n",
    "    z = deconv(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init, forward = hk.without_apply_rng(hk.transform(network_fn))\n",
    "optimizer = optax.adam(1e-4)\n",
    "probs = target_distribution(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state):\n",
    "    grads = grad(loss_fn)(params, x, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "\n",
    "def f1_score(params, x, y, pred=None):\n",
    "    pred = forward(params, x) > 0.5 if pred is None else pred > 0.5\n",
    "    pred, y = pred.flatten(), y.flatten()\n",
    "    tp = jnp.sum(pred * y)\n",
    "    fp = jnp.sum(pred * (1 - y))\n",
    "    fn = jnp.sum((1 - pred) * y)\n",
    "    return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "\n",
    "def loss_fn(params, x, y, pred=None):\n",
    "    pred = forward(params, x) if pred is None else pred\n",
    "    pred, y = pred.flatten(), y.flatten()\n",
    "    tp = jnp.sum(pred * y)\n",
    "    fp = jnp.sum(pred * (1 - y))\n",
    "    fn = jnp.sum((1 - pred) * y)\n",
    "    return 1 - (2 * tp / (2 * tp + fp + fn))  # 95 % sure this is correct\n",
    "\n",
    "\n",
    "def baseline(params, x, y, rng):\n",
    "    x = random.uniform(next(rng), x.shape)\n",
    "    pred = forward(params, x)\n",
    "    loss = loss_fn(params, x, y, pred)\n",
    "    f1 = f1_score(params, x, y, pred)\n",
    "    return loss, f1\n",
    "\n",
    "\n",
    "def evaluate(params, train_loader, val_loader, probs, rng, steps=20):\n",
    "    train_loss, train_f1 = [], []\n",
    "    val_loss, val_f1 = [], []\n",
    "    base_loss, base_f1 = [], []\n",
    "    for _ in range(steps):\n",
    "        _, y, _, _, lh, rh = next(train_loader)  # training\n",
    "        x = jnp.concatenate([lh, rh], axis=1)\n",
    "        train_loss.append(loss_fn(params, x, y))\n",
    "        train_f1.append(f1_score(params, x, y))\n",
    "        _, val_y, _, _, val_lh, val_rh = next(val_loader)  # validation\n",
    "        val_x = jnp.concatenate([val_lh, val_rh], axis=1)\n",
    "        val_loss.append(loss_fn(params, val_x, val_y))\n",
    "        val_f1.append(f1_score(params, val_x, val_y))\n",
    "        b_loss, b_f1 = baseline(params, x, y, probs, rng)  # baseline\n",
    "        base_loss.append(b_loss)\n",
    "        base_f1.append(b_f1)\n",
    "    return dict(\n",
    "        train_loss=np.mean(train_loss),\n",
    "        train_f1=np.mean(train_f1),\n",
    "        val_loss=np.mean(val_loss),\n",
    "        val_f1=np.mean(val_f1),\n",
    "        base_loss=np.mean(base_loss),\n",
    "        base_f1=np.mean(base_f1),\n",
    "    )\n",
    "\n",
    "\n",
    "def train(params, state, train_loader, val_loader, probs, rng, steps=n_steps):\n",
    "    wandb.init(project=\"neuroscope\", entity=\"syrkis\", config=args)\n",
    "    for step in tqdm(range(steps)):\n",
    "        img, cat, sup, cap, fmri = next(train_loader)\n",
    "        params, state = update(params, fmri, img, state)\n",
    "        if step % (steps // 100) == 0:\n",
    "            wandb.log(evaluate(params, train_loader, val_loader, probs, rng))\n",
    "    wandb.finish()\n",
    "    return params, state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "params = init(next(rng), jnp.concatenate([lh, rh], axis=1))\n",
    "state = optimizer.init(params)\n",
    "params, state = train(params, state, train_loader, val_loader, probs, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
