{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroscape playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import haiku as hk\n",
    "import optax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit\n",
    "import sys; sys.path.append(\"..\")\n",
    "import src\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use(\"dark_background\")\n",
    "jax.devices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "n_steps = 3000\n",
    "batch_size = 32\n",
    "n_samples = 2**13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "args_list = [\n",
    "    \"--model\",\n",
    "    \"fmri2cat\",\n",
    "    \"--roi\",\n",
    "    \"V1v,V1d\",\n",
    "    \"--machine\",\n",
    "    \"local\",\n",
    "    \"--subject\",\n",
    "    \"subj05\",\n",
    "    \"--batch_size\",\n",
    "    str(batch_size),\n",
    "    \"--n_samples\",\n",
    "    str(n_samples),\n",
    "    \"--n_steps\",\n",
    "    str(n_steps),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6272/6272 [02:40<00:00, 39.07it/s]\n",
      "100%|██████████| 1568/1568 [00:40<00:00, 39.15it/s]\n"
     ]
    }
   ],
   "source": [
    "args, config = src.get_setup(args_list)\n",
    "# if variable called lh not in scope\n",
    "if \"lh\" not in locals():\n",
    "    train_loader, val_loader, _ = src.get_loaders(args, config)\n",
    "    img, cat, sup, cap, lh, rh = next(train_loader)\n",
    "    img, cat, sup, cap, lh, rh = next(val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def target_distribution(train_loader, steps=n_samples // batch_size):\n",
    "    \"\"\"Compute the target distribution for the training data.\"\"\"\n",
    "    _, cat, _, _, _, _ = next(train_loader)\n",
    "    freqs = jnp.zeros_like(cat[0])\n",
    "    for _ in tqdm(range(steps)):\n",
    "        _, cat, _, _, _, _ = next(train_loader)\n",
    "        freqs += jnp.sum(cat, axis=0)\n",
    "    probs = freqs / (steps * batch_size)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def plot_metrics(metrics):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5), dpi=100)\n",
    "    for k, v in metrics.items():\n",
    "        if k.endswith(\"loss\"):\n",
    "            axes[0].plot(v, label=k[:-5])\n",
    "        if k.endswith(\"f1\"):\n",
    "            axes[1].plot(v, label=k[:-3])\n",
    "    axes[0].set_title(\"loss\")\n",
    "    axes[0].legend()\n",
    "    axes[1].set_title(\"f1\")\n",
    "    axes[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "mlp = hk.Sequential(\n",
    "    [\n",
    "        hk.Flatten(),\n",
    "        hk.Linear(512),\n",
    "        jax.nn.relu,\n",
    "        hk.Linear(512),\n",
    "        jax.nn.relu,\n",
    "        hk.Linear(80),\n",
    "        jax.nn.sigmoid,\n",
    "    ]\n",
    ")\n",
    "\n",
    "deconv = hk.Sequential(\n",
    "    [\n",
    "        hk.Conv2D(32, kernel_shape=3, padding=\"SAME\"),\n",
    "        jax.nn.relu,\n",
    "        hk.Conv2DTranspose(32, kernel_shape=3, padding=\"SAME\"),\n",
    "        jax.nn.relu,\n",
    "        hk.Conv2DTranspose(3, kernel_shape=3, padding=\"SAME\"),\n",
    "        jax.nn.sigmoid,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def network_fn(x):\n",
    "    z = mlp(x)\n",
    "    z = z.reshape((batch_size, 32, 32, 1))\n",
    "    z = deconv(z)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:04<00:00, 53.38it/s]\n"
     ]
    }
   ],
   "source": [
    "init, forward = hk.without_apply_rng(hk.transform(network_fn))\n",
    "optimizer = optax.adam(1e-4)\n",
    "probs = target_distribution(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def update(params, x, y, opt_state):\n",
    "    grads = grad(loss_fn)(params, x, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "\n",
    "def f1_score(params, x, y, pred=None):\n",
    "    pred = forward(params, x) > 0.5 if pred is None else pred > 0.5\n",
    "    pred, y = pred.flatten(), y.flatten()\n",
    "    tp = jnp.sum(pred * y)\n",
    "    fp = jnp.sum(pred * (1 - y))\n",
    "    fn = jnp.sum((1 - pred) * y)\n",
    "    return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "\n",
    "def loss_fn(params, x, y, pred=None):\n",
    "    pred = forward(params, x) if pred is None else pred\n",
    "    pred, y = pred.flatten(), y.flatten()\n",
    "    tp = jnp.sum(pred * y)\n",
    "    fp = jnp.sum(pred * (1 - y))\n",
    "    fn = jnp.sum((1 - pred) * y)\n",
    "    return 1 - (2 * tp / (2 * tp + fp + fn))  # 95 % sure this is correct\n",
    "\n",
    "\n",
    "def baseline(params, x, y, rng):\n",
    "    x = random.uniform(next(rng), x.shape)\n",
    "    pred = forward(params, x)\n",
    "    loss = loss_fn(params, x, y, pred)\n",
    "    f1 = f1_score(params, x, y, pred)\n",
    "    return loss, f1\n",
    "\n",
    "\n",
    "def evaluate(params, train_loader, val_loader, probs, rng, steps=20):\n",
    "    train_loss, train_f1 = [], []\n",
    "    val_loss, val_f1 = [], []\n",
    "    base_loss, base_f1 = [], []\n",
    "    for _ in range(steps):\n",
    "        _, y, _, _, lh, rh = next(train_loader)  # training\n",
    "        x = jnp.concatenate([lh, rh], axis=1)\n",
    "        train_loss.append(loss_fn(params, x, y))\n",
    "        train_f1.append(f1_score(params, x, y))\n",
    "        _, val_y, _, _, val_lh, val_rh = next(val_loader)  # validation\n",
    "        val_x = jnp.concatenate([val_lh, val_rh], axis=1)\n",
    "        val_loss.append(loss_fn(params, val_x, val_y))\n",
    "        val_f1.append(f1_score(params, val_x, val_y))\n",
    "        b_loss, b_f1 = baseline(params, x, y, probs, rng)  # baseline\n",
    "        base_loss.append(b_loss)\n",
    "        base_f1.append(b_f1)\n",
    "    return dict(\n",
    "        train_loss=np.mean(train_loss),\n",
    "        train_f1=np.mean(train_f1),\n",
    "        val_loss=np.mean(val_loss),\n",
    "        val_f1=np.mean(val_f1),\n",
    "        base_loss=np.mean(base_loss),\n",
    "        base_f1=np.mean(base_f1),\n",
    "    )\n",
    "\n",
    "\n",
    "def train(params, state, train_loader, val_loader, probs, rng, steps=n_steps):\n",
    "    wandb.init(project=\"neuroscope\", entity=\"syrkis\", config=args)\n",
    "    for step in tqdm(range(steps)):\n",
    "        img, cat, sup, cap, fmri = next(train_loader)\n",
    "        params, state = update(params, fmri, img, state)\n",
    "        if step % (steps // 100) == 0:\n",
    "            wandb.log(evaluate(params, train_loader, val_loader, probs, rng))\n",
    "    wandb.finish()\n",
    "    return params, state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nobr/neuroscope/wandb/run-20230517_095717-1vwx1nc9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/syrkis/neuroscope/runs/1vwx1nc9' target=\"_blank\">volcanic-cosmos-30</a></strong> to <a href='https://wandb.ai/syrkis/neuroscope' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/syrkis/neuroscope' target=\"_blank\">https://wandb.ai/syrkis/neuroscope</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/syrkis/neuroscope/runs/1vwx1nc9' target=\"_blank\">https://wandb.ai/syrkis/neuroscope/runs/1vwx1nc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [03:35<00:00, 13.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>base_f1</td><td>▁▂▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>base_loss</td><td>█▇▄▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>train_f1</td><td>▁▂▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_loss</td><td>█▇▄▄▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>val_f1</td><td>▁▂▅▅▇▆▆▇▇▇██▇▇▇██▇█▇▇▇▇▇▇▇██▇██▇▇█▇██▇▇▇</td></tr><tr><td>val_loss</td><td>█▇▄▄▂▃▃▂▂▂▁▁▂▂▂▁▁▂▁▂▂▂▂▂▂▂▁▁▂▁▁▂▂▁▂▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>base_f1</td><td>0.25916</td></tr><tr><td>base_loss</td><td>0.74084</td></tr><tr><td>train_f1</td><td>0.2722</td></tr><tr><td>train_loss</td><td>0.72832</td></tr><tr><td>val_f1</td><td>0.27005</td></tr><tr><td>val_loss</td><td>0.72983</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">volcanic-cosmos-30</strong> at: <a href='https://wandb.ai/syrkis/neuroscope/runs/1vwx1nc9' target=\"_blank\">https://wandb.ai/syrkis/neuroscope/runs/1vwx1nc9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230517_095717-1vwx1nc9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "params = init(next(rng), jnp.concatenate([lh, rh], axis=1))\n",
    "state = optimizer.init(params)\n",
    "params, state = train(params, state, train_loader, val_loader, probs, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
