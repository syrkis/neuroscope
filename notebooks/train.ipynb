{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroscape playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "from jax import pmap, vmap, grad, jit\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from functools import partial\n",
    "from src.train import update, evaluate\n",
    "from src.model import init, forward, loss_fn, network_fn\n",
    "from src.utils import get_args_and_config\n",
    "from src.data import get_loaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9840/9840 [01:16<00:00, 128.34it/s]\n"
     ]
    }
   ],
   "source": [
    "opt = optax.adam(1e-3)\n",
    "args, config = get_args_and_config()\n",
    "folds, _ = get_loaders(args, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'haiku' has no attribute 'Dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount_params\u001b[39m(params):\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msum\u001b[39m([np\u001b[39m.\u001b[39mprod(v\u001b[39m.\u001b[39mshape) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(params)])\n\u001b[0;32m---> 63\u001b[0m params_lst \u001b[39m=\u001b[39m train(folds, config)\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(folds, config)\u001b[0m\n\u001b[1;32m     12\u001b[0m config[\u001b[39m'\u001b[39m\u001b[39mgroup_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mgenerate_id()\n\u001b[1;32m     13\u001b[0m folds_lst \u001b[39m=\u001b[39m [make_fold(folds, fold) \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(folds))]  \u001b[39m# (train_data, val_data) list\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m params_lst \u001b[39m=\u001b[39m [init(\u001b[39mnext\u001b[39;49m(rng), folds[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m], folds[\u001b[39m0\u001b[39;49m][\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(folds))]\n\u001b[1;32m     15\u001b[0m train_fold \u001b[39m=\u001b[39m partial(train_fold_fn, config\u001b[39m=\u001b[39mconfig)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m idx, (params, fold) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(params_lst, folds_lst)):\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m config[\u001b[39m'\u001b[39m\u001b[39mgroup_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mgenerate_id()\n\u001b[1;32m     13\u001b[0m folds_lst \u001b[39m=\u001b[39m [make_fold(folds, fold) \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(folds))]  \u001b[39m# (train_data, val_data) list\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m params_lst \u001b[39m=\u001b[39m [init(\u001b[39mnext\u001b[39;49m(rng), folds[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m], folds[\u001b[39m0\u001b[39;49m][\u001b[39m1\u001b[39;49m]) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(folds))]\n\u001b[1;32m     15\u001b[0m train_fold \u001b[39m=\u001b[39m partial(train_fold_fn, config\u001b[39m=\u001b[39mconfig)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m idx, (params, fold) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(params_lst, folds_lst)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/transform.py:114\u001b[0m, in \u001b[0;36mwithout_state.<locals>.init_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit_fn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m   params, state \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49minit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    115\u001b[0m   \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m    116\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf your transformed function uses `hk.\u001b[39m\u001b[39m{\u001b[39m\u001b[39mget,set}_state` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mthen use `hk.transform_with_state`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/haiku/_src/transform.py:338\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.init_fn\u001b[0;34m(rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    337\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    339\u001b[0m   \u001b[39mexcept\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    340\u001b[0m     \u001b[39mraise\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/neuroscope/src/model.py:15\u001b[0m, in \u001b[0;36mnetwork_fn\u001b[0;34m(img, cat)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnetwork_fn\u001b[39m(img, cat):\n\u001b[1;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"network function\"\"\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     img \u001b[39m=\u001b[39m image_network_fn(img, cat)\n\u001b[1;32m     16\u001b[0m     cat \u001b[39m=\u001b[39m category_network_fn(img, cat)\n\u001b[1;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m fmri_network_fn(img, cat)\n",
      "File \u001b[0;32m~/neuroscope/src/model.py:37\u001b[0m, in \u001b[0;36mimage_network_fn\u001b[0;34m(img, cat)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimage_network_fn\u001b[39m(img, cat):\n\u001b[1;32m     32\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"network function\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     cnn \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m     34\u001b[0m         hk\u001b[39m.\u001b[39mConv2D(\u001b[39m16\u001b[39m, kernel_shape\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m), jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mgelu,\n\u001b[1;32m     35\u001b[0m         hk\u001b[39m.\u001b[39mConv2D(\u001b[39m32\u001b[39m, kernel_shape\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m), jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mgelu,\n\u001b[1;32m     36\u001b[0m         hk\u001b[39m.\u001b[39mConv2D(\u001b[39m64\u001b[39m, kernel_shape\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m), jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mgelu,\n\u001b[0;32m---> 37\u001b[0m         hk\u001b[39m.\u001b[39;49mDropout(config[\u001b[39m'\u001b[39m\u001b[39mdropout\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     38\u001b[0m         hk\u001b[39m.\u001b[39mConv2D(\u001b[39m128\u001b[39m, kernel_shape\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m), jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mgelu,\n\u001b[1;32m     39\u001b[0m         hk\u001b[39m.\u001b[39mFlatten(),\n\u001b[1;32m     40\u001b[0m     ])\n\u001b[1;32m     41\u001b[0m     mlp \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m     42\u001b[0m         hk\u001b[39m.\u001b[39mLinear(config[\u001b[39m'\u001b[39m\u001b[39mhidden_size\u001b[39m\u001b[39m'\u001b[39m]), jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mgelu,\n\u001b[1;32m     43\u001b[0m         hk\u001b[39m.\u001b[39mLinear(config[\u001b[39m'\u001b[39m\u001b[39mhidden_size\u001b[39m\u001b[39m'\u001b[39m]), jax\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mgelu,\n\u001b[1;32m     44\u001b[0m     ])\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m mlp(cnn(img))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'haiku' has no attribute 'Dropout'"
     ]
    }
   ],
   "source": [
    "rng = hk.PRNGSequence(jax.random.PRNGKey(42))\n",
    "\n",
    "# types\n",
    "Fold = Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]\n",
    "Batch = Fold\n",
    "\n",
    "\n",
    "# functions\n",
    "def train(folds: List[Fold], config: Dict) -> List[hk.Params]:\n",
    "    \"\"\"train function\"\"\"\n",
    "    # TODO: parallelize using pmap or vmap\n",
    "    config['group_name'] = wandb.util.generate_id()\n",
    "    folds_lst = [make_fold(folds, fold) for fold in range(len(folds))]  # (train_data, val_data) list\n",
    "    params_lst = [init(next(rng), folds[0][0], folds[0][1]) for _ in range(len(folds))]\n",
    "    train_fold = partial(train_fold_fn, config=config)\n",
    "    for idx, (params, fold) in enumerate(zip(params_lst, folds_lst)):\n",
    "        params_lst[idx] = train_fold(params, fold)\n",
    "    return params_lst\n",
    "\n",
    "\n",
    "def train_fold_fn(params, fold, config: Dict) -> hk.Params:\n",
    "    \"\"\"train_fold function\"\"\"\n",
    "    train_data, val_data = fold\n",
    "    config['param_count'] = count_params(params)\n",
    "    wandb.init(project=\"neuroscope\", entity='syrkis', config=config, group=config['group_name'])\n",
    "    opt_state = opt.init(params)\n",
    "    for step in range(config['n_steps']):\n",
    "        img, cat, fmri = get_batch(train_data, config['batch_size'])\n",
    "        params, opt_state = update(params, img, cat, fmri, opt_state)\n",
    "        if step % (config['n_steps'] // 100) == 0:\n",
    "            metrics = evaluate(params, train_data, val_data, get_batch)\n",
    "            wandb.log(metrics, step=step)\n",
    "    wandb.finish()\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_batch(fold: Fold, batch_size: int) -> Batch:\n",
    "    \"\"\"get a batch from a split\"\"\"\n",
    "    img, cat, fmri = fold\n",
    "    idx = np.random.randint(0, img.shape[0], batch_size)\n",
    "    return img[idx], cat[idx], fmri[idx]\n",
    "\n",
    "\n",
    "def make_fold(folds: List[Fold], fold: int) -> Batch:\n",
    "    \"\"\"make a fold from a list of folds\"\"\"\n",
    "    train_imgs = [f[0] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_cats = [f[1] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_fmris = [f[2] for f in folds[:fold] + folds[fold + 1:]]\n",
    "    train_data = tuple(map(jnp.concatenate, [train_imgs, train_cats, train_fmris]))\n",
    "    return train_data, folds[fold]\n",
    "\n",
    "\n",
    "@jit\n",
    "def update(params: hk.Params, img: jnp.ndarray, cat: jnp.ndarray, fmri: jnp.ndarray, opt_state: optax.OptState) -> Tuple[hk.Params, optax.OptState]:\n",
    "    grads = grad(loss_fn)(params, img, cat, fmri)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "def count_params(params):\n",
    "    return sum([np.prod(v.shape) for v in jax.tree_util.tree_leaves(params)])\n",
    "\n",
    "params_lst = train(folds, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
